{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/raw/AKIRA/AKIRA_030.jpg AKIRA_030.jpg\n",
      "196608 65536\n",
      "datasets/raw/Detective Conan/Detective Conan_012.jpg Detective Conan_012.jpg\n",
      "196608 65536\n",
      "datasets/raw/Durarara/Durarara_041.jpg Durarara_041.jpg\n",
      "196608 65536\n",
      "datasets/raw/Gurren Lagann/Gurren Lagann_034.jpg Gurren Lagann_034.jpg\n",
      "196608 65536\n",
      "datasets/raw/KILL la KILL/KILL la KILL_001.jpg KILL la KILL_001.jpg\n",
      "196608 65536\n",
      "datasets/raw/Mob Psycho 100/Mob Psycho 100_045.jpg Mob Psycho 100_045.jpg\n",
      "196608 65536\n",
      "datasets/raw/Naruto/Naruto_002.jpg Naruto_002.jpg\n",
      "196608 65536\n",
      "datasets/raw/Naruto/Naruto_012.jpg Naruto_012.jpg\n",
      "196608 65536\n",
      "datasets/raw/Night Is Short, Walk on Girl/Night Is Short, Walk on Girl_013.jpg Night Is Short, Walk on Girl_013.jpg\n",
      "196608 65536\n",
      "datasets/raw/Samurai Champloo/Samurai Champloo_027.jpg Samurai Champloo_027.jpg\n",
      "196608 65536\n",
      "datasets/raw/Samurai Champloo/Samurai Champloo_033.jpg Samurai Champloo_033.jpg\n",
      "196608 65536\n",
      "datasets/raw/SKET Dance/SKET Dance_033.jpg SKET Dance_033.jpg\n",
      "196608 65536\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset_util import remove_background\n",
    "from utils.dataset_util import combine_edges\n",
    "from utils.dataset_util import train_valid_test_split\n",
    "\n",
    "# remove_background(\"datasets/images\", \"datasets/images_without_bg\")\n",
    "combine_edges(\"datasets/raw\", \"datasets/combined_images\")\n",
    "train_valid_test_split(\"datasets/combined_images\",\"datasets\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cureent model generator epoch: 399\n",
      "load cureent model discriminator epoch: 399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4597/4597 [02:57<00:00, 25.96it/s]\n",
      "100%|██████████| 4597/4597 [03:00<00:00, 25.43it/s]\n",
      "100%|██████████| 4597/4597 [02:34<00:00, 29.80it/s]\n",
      "100%|██████████| 4597/4597 [02:36<00:00, 29.43it/s]\n",
      "100%|██████████| 4597/4597 [02:40<00:00, 28.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== Writing Discriminator Loss/train ===================\n",
      "=================== Finished Writing Discriminator Loss/train ===================\n",
      "=================== Writing Generator Loss/train ===================\n",
      "=================== Finished Writing Generator Loss/train ===================\n",
      "=================== Writing Discriminator Loss/valid ===================\n",
      "=================== Finished Writing Discriminator Loss/valid ===================\n",
      "=================== Writing Generator Loss/valid ===================\n",
      "=================== Finished Writing Generator Loss/valid ===================\n",
      "=================== Saving Model ===================\n",
      "=================== Finished Saving Model ===================\n",
      "=================== Saving Model ===================\n",
      "=================== Finished Saving Model ===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4597/4597 [03:05<00:00, 24.77it/s]\n",
      " 11%|█         | 488/4597 [00:19<02:19, 29.39it/s]"
     ]
    }
   ],
   "source": [
    "from model.pix2pix.model import Pix2Pix\n",
    "model = Pix2Pix()\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset_util import combine_edges\n",
    "combine_edges(\"datasets/single_set\", \"datasets/single_set_combined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.pix2pix.model import Pix2Pix\n",
    "from model.pix2pix.dataset import AnimeDataset\n",
    "from model.pix2pix import config\n",
    "from utils.dataset_util import denormalization\n",
    "import os\n",
    "from os import listdir\n",
    "from torchvision import transforms\n",
    "\n",
    "input_dir = \"datasets/single_set_combined\"\n",
    "output_dir = \"datasets/single\"\n",
    "\n",
    "trained_model = Pix2Pix()\n",
    "numOfImage = len(listdir(input_dir))\n",
    "dataloader = AnimeDataset(config.IMG_SIZE, config.BLANK_SPACE,input_dir, True).get_dataloader(numOfImage, shuffle=True)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "edges, images = dataloader.__iter__().__next__()\n",
    "fake_images = denormalization(trained_model.G(edges.to(config.DEVICE)))\n",
    "edges = denormalization(edges)\n",
    "images = denormalization(images)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "to_pil = transforms.ToPILImage()\n",
    "# idx =0\n",
    "for idx in range(images.shape[0]-1):\n",
    "    fake_image = to_pil(fake_images[idx])\n",
    "    edge = to_pil(edges[idx])\n",
    "    image = to_pil(images[idx])\n",
    "    edge.save(os.path.join(output_dir, f\"edge_{idx}.jpg\"))\n",
    "    image.save(os.path.join(output_dir, f\"image{idx}.jpg\"))\n",
    "    fake_image.save(os.path.join(output_dir, f\"fake_image{idx}.jpg\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp4471",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef06bb979018320f57ed897db756485fbddd611150a84cff135cf5b95a1f09a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
